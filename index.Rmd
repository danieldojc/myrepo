---
title: "Lady Gaga: Music versus Commerce"
author: "Daniël Dojčinović"
output:
    flexdashboard::flex_dashboard:
      storyboard: true
      theme: yeti
---


```{r setup, echo = FALSE, include=FALSE}
library(tidyverse)
library(spotifyr)
library(plotly)
library(dplyr)
library(compmus)
library(flexdashboard)
library(ggrepel)
library(ggplot2)
library(tidymodels)
library(ggdendro)
library(protoclust)
library(heatmaply)
library(cluster)
library(kknn)


The_Fame <- get_playlist_audio_features("", "0tP9ws8v5IahnYpFWWZWjG")
Born_This_Way <- get_playlist_audio_features("", "7z51IAcHQtFa6DIsIQOGZE")
Artpop <- get_playlist_audio_features("", "0Cu6DccnrVil7ZDnE1bhwP")
Cheek_To_Cheek <- get_playlist_audio_features("", "7JEg2pZCBZktul0xqjDLiQ")
Joanne <- get_playlist_audio_features("", "0F9TvACmRg9jnWdTpHlPkM")
A_Star_Is_Born_Soundtrack <- get_playlist_audio_features("", "4jbR1SeCh5XpitDHxLTlB3")
Chromatica <- get_playlist_audio_features("", "0A3GuU5dqjCO4viWOZbfBZ")

Lady_Gaga_Discography <- dplyr::bind_rows(
        The_Fame %>% mutate(category = "The Fame"),
        Born_This_Way %>% mutate(category =  "Born This Way"),
        Artpop %>% mutate(category = "Artpop"),
        Cheek_To_Cheek %>% mutate(category = "Cheek To Cheek"),
        Joanne %>% mutate(category = "Joanne"),
        A_Star_Is_Born_Soundtrack %>% mutate(category = "A Star Is Born"),
        Chromatica %>% mutate(category = "Chromatica")
    )
```


### Lady Gaga: from her **controversial** *The Fame* to her **newest release** *Chromatica*
Lady Gaga's first album, *The Fame*, was released in August 2008 and shot her into a life of pop stardom. From that moment, Gaga was one of the biggest artists in the world. Through the years, she has settled into this roll well and proven her musical diversity and range. After her debut album, she has released a variety of musical projects, ranging from mainstream pop to folk and jazz. I am very much interested in how the different musical elements are related to the commercial success of the albums.

This aim of this website is to display my small research on Lady Gaga's full discography. The albums I will compare are *The Fame*, *Born This Way*, *Artpop*, *Cheek To Cheek* (with Tony Bennett), *Joanne*, *A Star Is Born Soundtrack* (with Bradley Cooper) and *Chromatica*. To study the musical differences, I will first rank the albums by commercial success by looking at the total Spotify streams each album has. Then I will look at the musical differences of each album and conclude whether there is a relationship between the commercial succes and musical elements.

I expect that, due to Gaga's variety of musical styles, there will be quite some differences in the data of this portfolio. The energy and danceability will probably be quite high, with some outliers as she has also released a few slower songs. The valence will probably vary, as Gaga has both happier and sadder songs. Part of her genius is that she is able to combine these elements seamlessly into her music.



### **Ranking** all of Gaga's albums by the **amount of Spotify streams**
Before studying the musical elements of Lady Gaga's music, I have to rank all albums based on their commercial success. I first calculated the total amount of streams of each album on Spotify on February 28, 2021. As each album has a different amount of songs, I took the mean of streams per song on each album to have a fair ranking. My ranking will therefore be based on the average streams per song on each album.


1. **A Star Is Born Soundtrack (2018)**
- 3.253.821.459 streams (19 songs)
- Average of *171.253.761* streams per song

2. **The Fame (2008)**
- 1.455.977.263 streams (15 songs)
- Average of *97.065.151* streams per song

3. **Chromatica (2020)**:
- 1.415.855.164 streams (16 songs)
- Average of *88.474.260* streams per song

4. **Joanne (2016)**
- 1.182.601.651 (14 songs)
- Average of *84.471.547* streams per song

5. **Born This Way (2011)**
- 938.928.266 streams (17 songs)
- Average of *55.231.074* streams per song

6. **Artpop (2013)**
- 627.806.934 streams (14 songs)
- Average of *44.843.352* streams per song

7. **Cheek To Cheek (2014)**
- 116.065.257 streams (17 songs)
- Average of *6.827.368* streams per song

The only issue with this method of calculation is that all albums were released at different points in time, so some albums have naturally had more time to be streamed. I have not found a reliable source that provided me with data that can be fully equally compared. Another thing to take into consideration, is that *A Star Is Born* is the soundtrack of a movie, so it had much more exposure to a wider audience. However, it is still useful to look at this album as no two albums had the exact same marketing strategy.


### Comparing all albums by their **energy and loudness levels** and with a **histogram**.

#### Comparison by **energy**
```{r message=FALSE, warning=FALSE}
Lady_Gaga_Discography %>%
  ggplot(aes(x = energy)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(.~category)

```

****
To start off, I want to get an overview of all the albums compared to each other in their energy and loudness.
This first histogram shows that there is a quite a big difference in energy between all the albums. *Cheek To Cheek* scores quite a bit lower than *Chromatica* for example, which is logical because the it is a jazz record consisting of more slower, chiller songs. *Chromatica*, on the contrary, has only upbeat songs and scores very high on the energy ranking. This rule seems to apply for all her pop albums. *Artpop*, *The Fame*, and *Born This Way* score much higher than *Cheek To Cheek* (jazz) and *A Star Is Born*. *Joanne* is seems to be a combination, because it has both lower and higher energy scores. The album consists of both upbeat and slower songs, as it is a mix of pop, folk/country and rock elements.

#### Comparison by **loudness**
``` {r}

Lady_Gaga_Discography %>%
  ggplot(aes(x = loudness)) +
  geom_histogram() +
  facet_wrap(.~category)
```

****
This second histogram displays the loudness of each album. *A Star Is Born* and *Born This Way* are quite similar to each other. The albums are relatively loud and seem to do this consistently. *A Star Is Born* does have a high outlier, which could be explained by the harder rock songs on the album.
Another notable element is that *Cheek To Cheek* and *Chromatica* are divided over the whole graph, meaning that they have songs that are less loud (softer) and songs that are a little louder. However, *Chromatica* has more loud songs than Cheek To Cheek.
*Joanne* is much more centered in the middle.
*The Fame* and *Artpop* both have a higher level of loudness. The albums are quite consistent regarding this element.


### **Scatterplot** containing the **energy and valence** of each album

#### **The Fame**
```{r}
The_Fame <- ggplot(The_Fame, aes(x = valence, y = danceability, size = energy, label=track.name)) + geom_point() + geom_smooth()

ggplotly(The_Fame)

```

****
This plot is relatively cohesive and does not show a lot of extreme outliers. The most notable one is *Brown Eyes*, which has an energy level of 0.508 and is significantly smaller than the other songs. On the other side, *Disco Heaven* has the highest energy level of 0.946.



#### **Born This Way**
```{r}
Born_This_Way <- ggplot(Born_This_Way, aes(x = valence, y = danceability, size = energy, label=track.name)) + geom_point() + geom_smooth()

ggplotly(Born_This_Way)

```

****
This plot is already very different than the previous one as the line is pretty bent and curvy. The biggest outlier in energy is *Bloody Mary*. Its energy level is 0.637. The highest energy level is 0.970 from the song *ScheiBe*.



#### **Artpop**
```{r}
Artpop <- ggplot(Artpop, aes(x = valence, y = danceability, size = energy, label=track.name)) + geom_point() + geom_smooth()

ggplotly(Artpop)

```

****
This plot shows a bit of a curve. The biggest outlier is clearly *Dope*. Its energy level is 0.429. This is the lowest one until now, which makes sense as this song is a ballad and has is much slower and lower in valence and danceability than the other songs on this rather experimental album. On the other end, *Mary Jane Holland* has 0.967, which is the highest energy level of all songs on this album.



#### **Cheek To Cheek**
```{r}
Cheek_To_Cheek <- ggplot(Cheek_To_Cheek, aes(x = valence, y = danceability, size = energy, label=track.name)) + geom_point() + geom_smooth()

ggplotly(Cheek_To_Cheek)

```

****
The *Cheek To Cheek* plot shows a pretty straight line starting from a lower danceability level to a higher one. This jazz album is very different from the rest as the genre is already a big notifier of how the valence and danceability level could possibly impact its energy levels. The lowest energy score is 0.129 for *Ev'ry Time We Say Goodbye*, which is much lower than what was previously noted. This song is very slow and low in energy. Contrary to that song is *It Don't Mean A Thing (If It Ain't Got That Swing)*. Its energy level is 0.778, which is the highest here.



#### **Joanne**
```{r}
Joanne <- ggplot(Joanne, aes(x = valence, y = danceability, size = energy, label=track.name)) + geom_point() + geom_smooth()

ggplotly(Joanne)

```

****
This plot for the *Joanne* album shows a relatively straight line with a curve in the beginning. The biggest outlier in energy is the *Angel Down - Work Tape*. Its energy level is 0.237. This song is a different version of the song *Angel Down* which is on the same album. The energy is much lower as it is slower than most songs on the album. The highest energy level in this plot is 0.889 for the song *A-YO*.



#### **A Star Is Born (Soundtrack)**
```{r}
A_Star_Is_Born_Soundtrack <- ggplot(A_Star_Is_Born_Soundtrack, aes(x = valence, y = danceability, size = energy, label=track.name)) + geom_point() + geom_smooth()

ggplotly(A_Star_Is_Born_Soundtrack)

```

****
The line of this plot for the *A Star Is Born (Soundtrack)* album is pretty bent. The biggest energy outlier is *Is That Alright?*, which has an energy level of 0.279. This is also a slower song. The highest song, on the contrary, is *Black Eyes* (by Bradley Cooper, in this case) which energy level is 0.937.



#### **Chromatica**
```{r}
Chromatica <- ggplot(Chromatica, aes(x = valence, y = energy, size = danceability, label=track.name)) + geom_point() + geom_smooth()

ggplotly(Chromatica)

```

****
The last plot for *Chromatica* shows a curvy line. The biggest outlier is clearly *Chromatica II*, which has an energy level of 0.184. This is an instrumentaland orchestral track of 42 seconds and transitions seamlessly into *911*, which has an energy level of 0.789. This is the song that has the highest energy level of the album. It is quite interesting how two tracks, that are usually seen as one, can be so different in their energy levels.



### Studying and comparing all songs with the **highest energy level** with a **tempogram**

#### **Disco Heaven** (energy: 0.946)
``` {r}
Disco_Heaven <- get_tidy_audio_analysis("1uvJevFvRwq3AO1qzmXxhJ")

Disco_Heaven %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

```

****
This tempogram of Disco Heaven shows one very clear line around 225 BPM. There is also a more vague line around 510 BPM, but it is not a clear as the first one.

#### **ScheiBe** (energy: 0.970)
``` {r}
Disco_Heaven <- get_tidy_audio_analysis("7DXGKFjM7GNkJd32oXstGY")

Disco_Heaven %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

****
Theere is one clear line around 225 BPM and one that is clear but not as consistent around 550 BPM.

#### **Mary Jane Holland** (energy: 0.967)
``` {r}
Mary_Jane_Holland <- get_tidy_audio_analysis("0gMpKudmJ2ljDVAdIe9DmR")

Mary_Jane_Holland %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

****
This tempogram is not very clear. There is a line around 200 BPM, but it is interrupted quite often. The biggest interruption is around 150 seconds, which could be explained by the syncopation that is incorporated into the the rhythmic pattern of the beat. There are even some parts when the beat dissapears completely.


#### **It Don’t Mean A Thing (If It Ain’t Got That Swing)** (energy: 0.778)
``` {r}
It_Dont_Mean_A_Thing <- get_tidy_audio_analysis("13ZUcnlULdzCr9w5hnzja5")

It_Dont_Mean_A_Thing %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

****
This tempogram does not have one distinctive line. There is something around 210 BPM, but it is not very clear. It is understandable that the line is tempo to distinguish in this song, because this jazz track does not have a very clear beat pattern.


#### **A-YO** (energy: 0.889)
``` {r}
A_YO <- get_tidy_audio_analysis("6Az2Ll2CPnWYQ2BgiHf4Di")

A_YO %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

****
A-YO has the clearest tempogram with its distinguishable line around 300BPM.


#### **Black Eyes** (energy: 0.937)
``` {r}
Black_Eyes <- get_tidy_audio_analysis("7qrJKTyxjWDBpVofIYydTk")

Black_Eyes %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

****
*Black Eyes* shows a line around 300, but it is not very clear. It is for example interrupted around 75 seconds when a guitar solo appears in the song.


#### **911** (energy: 0.789)
``` {r}
nine_one_one <- get_tidy_audio_analysis("6qI0MU175Dk2DeoUjlrOpy")

nine_one_one %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

****
This *911* tempogram has two clear lines around 220 BPM and 440 BPM. This is logical as the latter is the double of the first one.

Altogether, it is clear that most of the highly energetic songs have clear lines, with one or two exceptions. Most of them have their tempo between 200 and 300 BPM, which is a up-beat tempo for a track. So, it makes sense that these were the songs with the highest energy on each album. My expectation of the songs that are higher in energy would also have a higher BPM is true.



### Studying and comparing all songs with the **lowest energy level** with a **chordogram**

#### **Brown Eyes** (energy: 0.508)
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

Brown_Eyes <-
  get_tidy_audio_analysis("6a3tkCh4IRkloHPVYxwtZ0") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Brown_Eyes %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",
    norm = "chebyshev"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

****
This chordogram shows Lady Gaga's song *Brown Eyes*. There are a lot of changes in the song, but the most notable one is around 165 seconds. At this point in the song, Gaga turns up the volume of her voice for the bridge. The present chords are Cmin, Amin and Cmaj. Cmaj and Amin are relative keys and Cmaj and Cmin are parallel keys. They are all connected in this way, up til the end when there is a fadeout in the song around 235 seconds.


#### **Bloody Mary** (energy: 0.637)
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

Bloody_Mary <-
  get_tidy_audio_analysis("53jnnqFSRGMDB9ADrNriCA") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Bloody_Mary %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",
    norm = "chebyshev"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

****
*Bloody Mary*'s chordogram is very different than the previous one as the colors are much lighter. The clearest trend is F#min that keeps on going throughout the song, except for during the intro and outro. There are not a lot of notable changes besides this one.

#### **Dope** (energy: 0.429)
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

Dope <-
  get_tidy_audio_analysis("1gPCk3KUE83rPdz9QqGsX9") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Dope %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",
    norm = "chebyshev"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

****
This chordogram of *Dope* shows a pretty clear structure. There is a 20-second intro, after which a verse starts. Around 45 seconds into the song, the pre-chorus starts, in which Bbmin is the most notable chord, that was also clearly present in the verse. This structure continues for the rest of the song.

#### **Ev'ry Time We Say Goodbye** (energy: 0.129)
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

Evry_Time_We_Say_Goodbye <-
  get_tidy_audio_analysis("0FvAAaYNHfM519NIP5MjWR") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Evry_Time_We_Say_Goodbye %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",
    norm = "chebyshev"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

****
*Ev'ry Time We Say Goodbye* also shows a clearly structures song. The most notable chords are Eb-maj, Fmin for a short part of the song, Emaj and C#min. These chords all lie close to each other.


#### **Angel Down - Work Tape** (energy: 0.237)
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

Angel_Down_Work_Tape <-
  get_tidy_audio_analysis("6vIi1fDLoB0cXdUqcZ6QRi") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Angel_Down_Work_Tape %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",
    norm = "chebyshev"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

****
*Angel Down - Work Tape* does not show a very diverse chordogram. Dmin is quite present in the first 40 seconds and D#min stays very present throughout the whole song. For the rest, the chords are very light which means they are not very present.


#### **Is That Alright?** (energy: 0.279)
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

Is_That_Alright <-
  get_tidy_audio_analysis("378u8gf9qpJ4ZhxHEvrodl") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Is_That_Alright %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",
    norm = "chebyshev"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

****
*Is That Alright?* shows a few present chords such as Ab-maj for a short part of the song and Amaj that is quite strong throughout the whole song. There are chords like Amin and Fmaj that show a smaller present, but are still there.


#### **Chromatica II** (energy: 0.184)
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

Chromatica_II <-
  get_tidy_audio_analysis("0oQc0F6KUE7QY7k5TU6bic") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Chromatica_II %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",
    norm = "chebyshev"
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

****
*Chromatica II* has three clear parts. The first part is the intro, the second part shows no strong presence of chords and the third part shows a strong presence of Fmin, Ebmaj, Dmin and C#min. This track is instrumental and orchestral so it is different from all of the other songs.


### Comparing the first and last tempograms with **cepstrograms** using **timbre**.

#### **Disco Heaven** (from *The Fame*)
``` {r}
Disco_Heaven <-
  get_tidy_audio_analysis("1uvJevFvRwq3AO1qzmXxhJ") %>%
  compmus_align(sections, segments) %>%                     
  select(sections) %>%                                      
  unnest(sections) %>%                                     
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"             
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"             
      )
  )

Disco_Heaven %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

****
I will now compare the first and last song with the highest energy to find any similarities and differences. This cepstrogram shows Lady Gaga's song *Disco Heaven* from the album *The Fame*. I plotted it in sections, as I find this the clearest overview of the cepstrogram. It is divided very equally. c02 is clearly the strongest one here.


#### **911** (from *Chromatica*)
``` {r}
nine_one_one <-
  get_tidy_audio_analysis("6qI0MU175Dk2DeoUjlrOpy") %>%
  compmus_align(sections, segments) %>%                     
  select(sections) %>%                                      
  unnest(sections) %>%                                     
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"             
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"             
      )
  )

nine_one_one %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

****
This cepstrogram shows Lady Gaga's song *911* from the album *Chromatica*. This one is different from the previous, because there is a lot more variety here. c02 and c01 are the most prominent, but there are definitely some more that are present. It started to get dark from c07 to all the way up.



### Difference between Gaga's most and least streamed song with a **Chromagram**?

#### **Shallow** (1.445.044.322 streams on 28-02-2020)

``` {r}

Shallow <-
  get_tidy_audio_analysis("2VxeLyX666F8uXCJ0dZF8B") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

Shallow %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

****
There are a few notable trends in this chromagram. The most consistent note is the G. Note that the other present notes are the ones that do not have an accidental (# or b). Only F#/Gb has a few moments in which appears, which is later in the song. This makes sense, because the song is in G-major, so the only note that has an accidental is F#.


#### **On A Clear Day (You Can See Forever)** (56.827 streams on 28-02-2020)

``` {r}

On_A_Clear_Day <-
  get_tidy_audio_analysis("3BjrO5IkvIho2URXIRAyqA") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

On_A_Clear_Day %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

****
This chromagram has much more changes. This is logical as this song is a jazz song, compared to the previous song that was pop. Jazz usually has more musical changes and shows more diversity when it comes to its musical elements. The prominent notes all appear very shortly, except for the D#/Eb that stays longer at a later point in the song.



### Can Spotify differentiate between Gaga's **least streamed, most streamed and the album in between** with a **confusion matrix**?
``` {r}
Cheek_To_Cheek <- get_playlist_audio_features("spotify", "7JEg2pZCBZktul0xqjDLiQ")
A_Star_Is_Born_Soundtrack <- get_playlist_audio_features("spotify", "4jbR1SeCh5XpitDHxLTlB3")
Joanne <- get_playlist_audio_features("spotify", "0F9TvACmRg9jnWdTpHlPkM")
Gaga <-
  bind_rows(
    Cheek_To_Cheek %>% mutate(playlist = "Cheek to Cheek") %>% slice_head(n = 20),
    A_Star_Is_Born_Soundtrack %>% mutate(playlist = "A Star Is Born") %>% slice_head(n = 20),
    Joanne %>% mutate(playlist = "Joanne") %>% slice_head(n = 20)
  ) 


Gaga_features <-
  Gaga %>%  
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))


Gaga_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Gaga_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())


Gaga_cv <- Gaga_features %>% vfold_cv(5)


knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
Gaga_knn <- 
  workflow() %>% 
  add_recipe(Gaga_recipe) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    Gaga_cv, 
    control = control_resamples(save_pred = TRUE)
  )

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  
  
Gaga_knn %>% get_conf_mat()

Gaga_knn %>% get_conf_mat() %>% autoplot(type = "heatmap")

```

***
There are a few interesting thins in this confusion matrix. Spotify's API seems to be very sure about recognizing *Cheek To Cheek*. This is not a surprise, because this album is very different than the other, as I have explained before. The musical elements from this album are simply outliers when compared to the other albums.
*Joanne* and *A Star Is Born* were written not too far apart from each other, so it is not strange that this matrix finds some similarities when looking at *Joanne* compared to *A Star Is Born*.


### Is there a clear and distinctive **relationship** between **music and commerce** in Gaga's music?
The first histogram that plots all the albums by energy level does not show a clear difference between the commercially successful albums versus the less successful ones. The same seems to be true for loudness. I expected that the more energetic and louder albums would be more successful, but this is not necessarily true. The most popular albums might be higher in energy and loudness, but this also seems to be the case for the less popular ones.

The songs that are higher in energy also have a higher BPM. This is my conclusion from the tempograms. On the other hand, the songs that are lower in energy seem to have a more stable trend. Most of these songs, that I plotted in a chordogram, seem to use more minor chords. This could mean that the songs that are lower in energy, are also the songs that Gaga writes in a minor key. But there does not seem to be a clear difference between the commercially successful albums and certain musical elements here.

The confusion matrix shows some interesting data. *Cheek To Cheek* is very different than the other albums. This also translates in the commercial success, as this album got significantly less streams than Gaga’s other albums. Could this mean that when she released a pop project, it is simply streamed more because her fans are used to it? I do think so. But besides that, pop music also has a much bigger platform on Spotify than jazz music. There are more people listening to pop on Spotify than they do to jazz.

Altogether, I can conclude that while there may not be a strong difference between Gaga’s projects, there are a few things to be said. The higher the energy and danceability, the more success a song/album will probably have. *Cheek To Cheek* has proven that pop is much more popular for Gaga. But as she released more projects in the future, it will be interesting to see where that data takes us.
